{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eef90421-a980-41a0-9209-a9da1955774b",
   "metadata": {},
   "source": [
    "### <div align=\"center\">Supervised Machine Learning - Regression</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d1116d-b790-4d6c-8575-86b4fde148c7",
   "metadata": {},
   "source": [
    "##### 3.1: Simple Linear Regression\n",
    "##### 3.2: Multiple Linear Regression\n",
    "- Simple Linear Regression (One independent variable): y = mx + c (Slope (m) - coefficient, Intercept (c) - line cut at y axis, y is dependent variable).\n",
    "- Linear regression helps to establish the relationship between dependent and independent variables.\n",
    "- Multiple Linear Regression (Multiple independent variable): y=m1⋅x1+m2⋅x2+…+b ; m1,m2: coefficients, x1,x2: independent variables and b: intercept\n",
    "- Slop is also called Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252c0237-9f93-4d29-9951-33de30341f70",
   "metadata": {},
   "source": [
    "##### 3.5: Cost Function\n",
    "- Best fit line is finding the appropriate line for slope m and intercept b.\n",
    "- Understanding the cost function is essential for understanding Gradient Descent.\n",
    "- Gradient Descent is the most important concept in the world of Supervised Machine Learning.\n",
    "- Line, Slope, Intercept are the essential basic terms.\n",
    "- Error/Loss: Difference between the predicted and actual Y value.\n",
    "- Mean Absolute Error (MAE): The average of errors, disregarding their direction. It is the average differences between prediction and actual observation.\n",
    "- Mean Squared Error (MSE): The average of squared differences between prediction and actual observation. It effectively highlights larger errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587cabd6-0a0b-4afa-8639-83136df7f9bc",
   "metadata": {},
   "source": [
    "##### 3.6: Derivatives and Partial Derivatives\n",
    "- Slope of a line at a given point is Derivative.\n",
    "- Derivative: y′ = x0 + x0**n−1.\n",
    "- Slope is used for linear equations, whereas Derivative is used for non-linear equations.\n",
    "- Slope is constant, whereas Derivative is a function.\n",
    "- The purpose of a Partial Derivative is to measure how a function changes as one of its variables is varied while keeping the other variables constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4bdac7-cf75-4108-bcb3-84be7e09d110",
   "metadata": {},
   "source": [
    "##### 3.7: Chain Rule\n",
    "- Chain rule: A technique used to compute the derivative of a function composed of multiple functions.\n",
    "- Application: Chain rule will be used in the Gradient Descent Technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d93a359-e01f-4201-a8be-0bb403039f34",
   "metadata": {},
   "source": [
    "##### 3.10: Gradient Descent Theory\n",
    "- Gradient Descent: An optimization method used in linear regression to find the best-fit line by iteratively adjusting the slope (m) and intercept (b) to minimize the cost function, usually the mean squared error (MSE).\n",
    "- Efficiency: Since testing every combination for MSE is impractical, gradient descent efficiently minimizes MSE with fewer iterative adjustments.\n",
    "- Mean Squared Error (MSE): MSE= 1/n ∑[yi − (mxi + b)] ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eec6eb-6a8a-4a78-af72-78116a815821",
   "metadata": {},
   "source": [
    "##### 3.11: Gradient Descent Implementation\n",
    "- In a role as a Data Scientist or AI Engineer, your daily tasks will not typically involve implementing Gradient Descent. Instead, you will use ML libraries. However, a solid understanding of this concept is beneficial for both your work and potential interviews.\n",
    "- Adjusting the learning rate and epochs based on observed outputs (m, L) will enable you to obtain the desired outcomes in the Gradient Descent Implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e778aaf7-ddc2-4590-a179-3662f51c214f",
   "metadata": {},
   "source": [
    "##### 3.12: Why MSE (Not MAE)\n",
    "- Mean Squared Error (MSE) is our go-to for calculating Gradient Descent because:\n",
    "  1. It's sensitive to outliers.\n",
    "  2. It's continuously differentiable.\n",
    "- In rare scenarios, Mean Absolute Error (MAE) is our pick for Gradient Descent when we're dealing with lots of outliers.\n",
    "- Even though these principles are basic, in real-world scenarios, you'll be using machine learning libraries directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81d3220-cd57-4e33-9f85-1f6c97732372",
   "metadata": {},
   "source": [
    "##### 3.13: Model Evaluation (Train, Test Split)\n",
    "- Just as obtaining a driver's license involves passing a test, not just learning to drive, machine learning models require splitting the dataset into training and testing parts and evaluating the model's precision.\n",
    "- We utilize the train_test_split() function from the sklearn library for this purpose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007cda91-f684-4e8b-af9f-ecd13761d625",
   "metadata": {},
   "source": [
    "##### 3.14: Model Evaluation - Metrics\n",
    "- To evaluate the performance of a Machine Learning model, we can use metrics such as MSE, MAE, or R2 score.\n",
    "- The R2 score is easier to interpret, compared to other metrics.\n",
    "- The parameter random_state is used in the train_test_split() function to ensure reproducibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8730101b-4ef9-45f8-9153-e2efb458d0fd",
   "metadata": {},
   "source": [
    "##### 3.18: Data preprocessing - One hot encoding\n",
    "- Data Science/AI Project Stages\n",
    "  Data Collection -> Data Preprocessing (Cleaning bad data, creating new features - feature engineering called one hot encoding) -> Model Training & Evaluation -> Model Tuning\n",
    "- Multicollinearity occurs when two or more independent variables are highly correlated, making it difficult to distinguish their individual effects on the dependent variable.\n",
    "- In simple terms, computers understand numbers, not text. The process of turning text into numbers is called encoding.\n",
    "- We use label encoding for ordinal categories that have a specific order. For nominal categories, which don't have an order, we use one-hot encoding.\n",
    "- One-hot encoding transforms categorical data into a binary vector format that's easier for machine learning to understand. Each category is represented by a binary vector, with a \"1\" at the position corresponding to the category and \"0\"s everywhere else.\n",
    "- Multicollinearity is a situation where two or more independent variables are closely related. It makes it hard to differentiate their separate effects.\n",
    "- To handle multicollinearity, we remove one of the columns after/during the one-hot encoding process.\n",
    "- The Pandas library includes a built-in function named get_dummies() for implementing one-hot encoding. By using the drop_first parameter, we can eliminate the first dummy column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af901a67-ac4e-44ee-9dfb-8934014c3048",
   "metadata": {},
   "source": [
    "##### 3.20: Polynomial Regression\n",
    "- Simple linear regression models a straight-line (y=b0+b1x) relationship between a dependent variable y and an independent variable x. Polynomial regression extends this by including higher powers of x for complex, non-linear relationships.\n",
    "- y = b0 + b1*X + b2*X**2 + b3*X**3 + .... + bnX**n ; b0, b1,…,bn - coefficients ; n = degree\n",
    "- Polynomial Regression with degree=1 is nothing but a Linear Regression.\n",
    "- Deciding the degree will be based on trial and error, as well as domain knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3713cce-7273-494f-8b56-4dbd906c4901",
   "metadata": {},
   "source": [
    "##### 3.23: Overfitting and Underfitting\n",
    "- Overfitting: Occurs when a model learns too much detail and noise from the training data, affecting its performance on new data.\n",
    "- Under fitting: Happens when a model is too simple and cannot learn the data pattern, leading to poor performance on all data.\n",
    "- Balanced Fit: Achieved when a model accurately learns the training data's patterns and performs well on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070f7a5e-57d5-4de7-9e7a-507e9d83475c",
   "metadata": {},
   "source": [
    "##### 3.24: Reasons and Remedies for Over fitting/Under fitting\n",
    "- Overfitting can happen due to any one or combination of the following points:\n",
    "  1. Reason: Poor model, hyper parameters selection: Solution: Better model, hyper parameters selection (Where we try to cover each point and line becomes zigzag instead curve).\n",
    "  2. Reason: Insufficient training data, Solution: Sufficient training data\n",
    "  3. Reason: Poor feature selection, Solution: Careful feature selection\n",
    "  4. Reason: Inadequate validation, Solution: Adequate validation (If train and test datasets are from same area then points available in different area will not fit into derived model).\n",
    "  5. Reason: Lack of regularization, Solution: Apply regularization (It is a technique used to reduce overfitting but if we apply too much regularization then our model will go from one extream to another extream means overfit to underfit).\n",
    "- Under fitting can happen due to any one or combination of the following points:\n",
    "  1. Reason: Too simple model: Solution: Use a complex model that can capture data patterns\n",
    "  2. Reason: Insufficient training data, Solution: Sufficient training data\n",
    "  3. Reason: Insufficient features / Poor feature engineering: Solution: Better feature selection/engineering\n",
    "  4. Reason: Insufficient training time, Solution: Sufficient training time (No of epoch/iterations should be more).\n",
    "  5. Reason: Inadequate validation, Solution: Adequate validation\n",
    "  6. Reason: Excessive regularization, Solution: Adequate regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf195d9-327a-44e2-b794-6a0021f10449",
   "metadata": {},
   "source": [
    "##### 3.25: L1 and L2 Regularization\n",
    "- L1 and L2 regularization are effective tools for minimizing over fitting. When L2 regularization is applied to Linear Regression, it transforms into Ridge Regression. In below use case we have added/increased the penalty and improved the regularization.\n",
    "- In the same vein, L1 Regularization leads to what we commonly call Lasso Regression.\n",
    "- Linear Regression too can encounter over fitting issues if the number of features is excessive.\n",
    "- The choice between Ridge or Lasso Regression and parameters like Alpha is contingent on multiple factors and is typically determined through a process of trial and error.\n",
    "- Linear regression also can have overfitting when there are too many feature and regularization is used to reduce the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5ff182-bf33-4317-ac47-4dabb6e52857",
   "metadata": {},
   "source": [
    "##### 3.26: Bias Variance Trade off\n",
    "- Bias is a measurement of how accurately a model can capture a pattern in a training dataset.\n",
    "- Bias occurs when an algorithm misses significant patterns in the data due to its simplicity, while Variance occurs when an algorithm changes significantly based on minor differences in the training data.\n",
    "- BUVO: Bias-Underfitting (High bias often leads to underfitting), Variance-Overfitting.\n",
    "- Overfitting: Training Error - Low, Test Error - High (The model has learned too much detail from the training data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3f6ed6-6172-4f39-8c8b-d555b194808c",
   "metadata": {},
   "source": [
    "### Linear Regression Use case\n",
    "You are a data scientist / AI engineer at a healthcare consulting firm. You have been provided with a dataset named **`\"patient_health_data.csv\"`**, which includes records of various health indicators for a group of patients. The dataset comprises the following columns:\n",
    "\n",
    "- `age:` The age of the patient.\n",
    "- `bmi:` Body Mass Index of the patient.\n",
    "- `blood_pressure:` The blood pressure of the patient.\n",
    "- `cholesterol:` Cholesterol levels of the patient.\n",
    "- `glucose:` Glucose levels of the patient.\n",
    "- `insulin:` Insulin levels of the patient.\n",
    "- `heart_rate:` Heart rate of the patient.\n",
    "- `activity_level:` Activity level of the patient.\n",
    "- `diet_quality:` Quality of diet of the patient.\n",
    "- `smoking_status:` Whether the patient smokes (Yes or No).\n",
    "- `alcohol_intake:` The amount of alcohol intake by the patient.\n",
    "- `health_risk_score:` A composite score representing the overall health risk of a patient.\n",
    "\n",
    "Your task is to use this dataset to build a linear regression model to predict the health risk score based on the given predictor variables. Additionally, you will use L1 (Lasso) and L2 (Ridge) regularization techniques to improve the model's performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4baae9-dc61-4119-a9df-bd3b99b1cf2d",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d8cd2b0-52fe-477e-81ec-638dd313e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911d6b2b-6c0c-4299-9430-c929d3bd5a95",
   "metadata": {},
   "source": [
    "#### Step 1: Data Preparation and Exploration\n",
    "1. Import the data from the **`\"patient_health_data.csv\"`** file and store it in a variable df.\n",
    "2. Display the number of rows and columns in the dataset.\n",
    "3. Display the first few rows of the dataset to get an overview.\n",
    "4. Check for any missing values in the dataset and handle them appropriately.\n",
    "5. Encode the categorical variable `'smoking_status'` by converting 'Yes' to 1 and 'No' to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "996380ac-467b-4a3d-ab83-0d1317870f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns: (250, 12)\n",
      "First few rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>glucose</th>\n",
       "      <th>insulin</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>activity_level</th>\n",
       "      <th>diet_quality</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>alcohol_intake</th>\n",
       "      <th>health_risk_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>24.865215</td>\n",
       "      <td>122.347094</td>\n",
       "      <td>165.730375</td>\n",
       "      <td>149.289441</td>\n",
       "      <td>22.306844</td>\n",
       "      <td>75.866391</td>\n",
       "      <td>1.180237</td>\n",
       "      <td>7.675409</td>\n",
       "      <td>No</td>\n",
       "      <td>0.824123</td>\n",
       "      <td>150.547752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>19.103168</td>\n",
       "      <td>136.852028</td>\n",
       "      <td>260.610781</td>\n",
       "      <td>158.584646</td>\n",
       "      <td>13.869817</td>\n",
       "      <td>69.481114</td>\n",
       "      <td>7.634622</td>\n",
       "      <td>8.933057</td>\n",
       "      <td>No</td>\n",
       "      <td>0.852910</td>\n",
       "      <td>160.320350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>22.316562</td>\n",
       "      <td>137.592457</td>\n",
       "      <td>177.342582</td>\n",
       "      <td>178.760166</td>\n",
       "      <td>22.849816</td>\n",
       "      <td>69.386962</td>\n",
       "      <td>7.917398</td>\n",
       "      <td>3.501119</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.740542</td>\n",
       "      <td>187.487398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>22.196893</td>\n",
       "      <td>153.164775</td>\n",
       "      <td>234.594764</td>\n",
       "      <td>136.351714</td>\n",
       "      <td>15.140336</td>\n",
       "      <td>95.348387</td>\n",
       "      <td>3.192910</td>\n",
       "      <td>2.745585</td>\n",
       "      <td>No</td>\n",
       "      <td>2.226231</td>\n",
       "      <td>148.773138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>29.837173</td>\n",
       "      <td>92.768973</td>\n",
       "      <td>276.106498</td>\n",
       "      <td>158.753516</td>\n",
       "      <td>17.228576</td>\n",
       "      <td>77.680975</td>\n",
       "      <td>7.044026</td>\n",
       "      <td>8.918348</td>\n",
       "      <td>No</td>\n",
       "      <td>3.944011</td>\n",
       "      <td>170.609655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        bmi  blood_pressure  cholesterol     glucose    insulin  \\\n",
       "0   58  24.865215      122.347094   165.730375  149.289441  22.306844   \n",
       "1   71  19.103168      136.852028   260.610781  158.584646  13.869817   \n",
       "2   48  22.316562      137.592457   177.342582  178.760166  22.849816   \n",
       "3   34  22.196893      153.164775   234.594764  136.351714  15.140336   \n",
       "4   62  29.837173       92.768973   276.106498  158.753516  17.228576   \n",
       "\n",
       "   heart_rate  activity_level  diet_quality smoking_status  alcohol_intake  \\\n",
       "0   75.866391        1.180237      7.675409             No        0.824123   \n",
       "1   69.481114        7.634622      8.933057             No        0.852910   \n",
       "2   69.386962        7.917398      3.501119            Yes        4.740542   \n",
       "3   95.348387        3.192910      2.745585             No        2.226231   \n",
       "4   77.680975        7.044026      8.918348             No        3.944011   \n",
       "\n",
       "   health_risk_score  \n",
       "0         150.547752  \n",
       "1         160.320350  \n",
       "2         187.487398  \n",
       "3         148.773138  \n",
       "4         170.609655  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data from the \"patient_health_data.csv\" file and store it in a variable 'df'\n",
    "df = pd.read_csv(\"../data/patient_health_data.csv\")\n",
    "\n",
    "# Display the number of rows and columns in the dataset\n",
    "print(\"Number of rows and columns:\", df.shape)\n",
    "\n",
    "# Display the first few rows of the dataset to get an overview\n",
    "print(\"First few rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31d0030a-8df0-4cfa-82d3-030f2fa5fcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in the dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age                  0\n",
       "bmi                  0\n",
       "blood_pressure       0\n",
       "cholesterol          0\n",
       "glucose              0\n",
       "insulin              0\n",
       "heart_rate           0\n",
       "activity_level       0\n",
       "diet_quality         0\n",
       "smoking_status       0\n",
       "alcohol_intake       0\n",
       "health_risk_score    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for any missing values in the dataset and handle them appropriately\n",
    "print(\"Missing values in the dataset:\")\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e97c30c-8f49-434c-854e-7105fc1c8b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorical variable 'smoking_status' by converting 'Yes' to 1 and 'No' to 0.\n",
    "df['smoking_status'] = df['smoking_status'].apply(lambda x: 1 if x == 'Yes' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f182ead7-48a5-4b34-af92-54b9c8cfabe4",
   "metadata": {},
   "source": [
    "#### Step 2: Train Linear Regression Models\n",
    "1. Select the features and the target variable for modeling.\n",
    "2. Split the data into training and test sets with a test size of 25%.\n",
    "3. Initialize and train a Linear Regression model, and evaluate its performance using R-squared.\n",
    "4. Initialize and train a Lasso Regression model with various alpha values provided in a list: [0.01, 0.1, 1.0, 10.0], and evaluate its performance using R-squared.\n",
    "5. Initialize and train a Ridge Regression model with various alpha values provided in a list: [0.01, 0.1, 1.0, 10.0], and evaluate its performance using R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b865a284-6c45-43bc-9174-99d263b90373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>glucose</th>\n",
       "      <th>insulin</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>activity_level</th>\n",
       "      <th>diet_quality</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>alcohol_intake</th>\n",
       "      <th>health_risk_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>24.865215</td>\n",
       "      <td>122.347094</td>\n",
       "      <td>165.730375</td>\n",
       "      <td>149.289441</td>\n",
       "      <td>22.306844</td>\n",
       "      <td>75.866391</td>\n",
       "      <td>1.180237</td>\n",
       "      <td>7.675409</td>\n",
       "      <td>0</td>\n",
       "      <td>0.824123</td>\n",
       "      <td>150.547752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>19.103168</td>\n",
       "      <td>136.852028</td>\n",
       "      <td>260.610781</td>\n",
       "      <td>158.584646</td>\n",
       "      <td>13.869817</td>\n",
       "      <td>69.481114</td>\n",
       "      <td>7.634622</td>\n",
       "      <td>8.933057</td>\n",
       "      <td>0</td>\n",
       "      <td>0.852910</td>\n",
       "      <td>160.320350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>22.316562</td>\n",
       "      <td>137.592457</td>\n",
       "      <td>177.342582</td>\n",
       "      <td>178.760166</td>\n",
       "      <td>22.849816</td>\n",
       "      <td>69.386962</td>\n",
       "      <td>7.917398</td>\n",
       "      <td>3.501119</td>\n",
       "      <td>1</td>\n",
       "      <td>4.740542</td>\n",
       "      <td>187.487398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>22.196893</td>\n",
       "      <td>153.164775</td>\n",
       "      <td>234.594764</td>\n",
       "      <td>136.351714</td>\n",
       "      <td>15.140336</td>\n",
       "      <td>95.348387</td>\n",
       "      <td>3.192910</td>\n",
       "      <td>2.745585</td>\n",
       "      <td>0</td>\n",
       "      <td>2.226231</td>\n",
       "      <td>148.773138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>29.837173</td>\n",
       "      <td>92.768973</td>\n",
       "      <td>276.106498</td>\n",
       "      <td>158.753516</td>\n",
       "      <td>17.228576</td>\n",
       "      <td>77.680975</td>\n",
       "      <td>7.044026</td>\n",
       "      <td>8.918348</td>\n",
       "      <td>0</td>\n",
       "      <td>3.944011</td>\n",
       "      <td>170.609655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        bmi  blood_pressure  cholesterol     glucose    insulin  \\\n",
       "0   58  24.865215      122.347094   165.730375  149.289441  22.306844   \n",
       "1   71  19.103168      136.852028   260.610781  158.584646  13.869817   \n",
       "2   48  22.316562      137.592457   177.342582  178.760166  22.849816   \n",
       "3   34  22.196893      153.164775   234.594764  136.351714  15.140336   \n",
       "4   62  29.837173       92.768973   276.106498  158.753516  17.228576   \n",
       "\n",
       "   heart_rate  activity_level  diet_quality  smoking_status  alcohol_intake  \\\n",
       "0   75.866391        1.180237      7.675409               0        0.824123   \n",
       "1   69.481114        7.634622      8.933057               0        0.852910   \n",
       "2   69.386962        7.917398      3.501119               1        4.740542   \n",
       "3   95.348387        3.192910      2.745585               0        2.226231   \n",
       "4   77.680975        7.044026      8.918348               0        3.944011   \n",
       "\n",
       "   health_risk_score  \n",
       "0         150.547752  \n",
       "1         160.320350  \n",
       "2         187.487398  \n",
       "3         148.773138  \n",
       "4         170.609655  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c2bf3da-4286-482d-808b-ba0881aff431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features and target variable for modeling\n",
    "X = df.drop(['health_risk_score'], axis=1)\n",
    "y = df['health_risk_score']\n",
    "\n",
    "# Split the data into training and test sets with a test size of 25%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35790cd6-723d-473f-b332-ef008b4fd000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R-squared: 0.7643620906757489\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train a Linear Regression model, and evaluate its performance using R-squared\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "linear_r2 = linear_model.score(X_test, y_test)\n",
    "print(\"Linear Regression R-squared:\", linear_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1dc8d02-3971-4147-aad1-0ab39b682a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression R-squared (alpha=0.01): 0.7645437646395714\n",
      "Lasso Regression R-squared (alpha=0.1): 0.7660509914802165\n",
      "Lasso Regression R-squared (alpha=1.0): 0.781976368357514\n",
      "Lasso Regression R-squared (alpha=10.0): 0.7873364302158368\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train a Lasso Regression model with various alpha values provided in a list, and evaluate its performance using R-squared\n",
    "lasso_alphas = [0.01, 0.1, 1.0, 10.0]\n",
    "for alpha in lasso_alphas:\n",
    "    lasso_model = Lasso(alpha=alpha)\n",
    "    lasso_model.fit(X_train, y_train)\n",
    "    lasso_r2 = lasso_model.score(X_test, y_test)\n",
    "    print(f\"Lasso Regression R-squared (alpha={alpha}):\", lasso_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827191db-1e9d-4aa3-b770-d7cac0ccbb22",
   "metadata": {},
   "source": [
    "- Lasso regression with alpha `1.0` gives a little improvement in accuracy score, `0.78` as opposed to `0.76` with plain Linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d70f6972-cac2-4d81-84d8-71d3aeccfe95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression R-squared (alpha=0.01): 0.7643631589390539\n",
      "Ridge Regression R-squared (alpha=0.1): 0.7643727707489341\n",
      "Ridge Regression R-squared (alpha=1.0): 0.7644686367656156\n",
      "Ridge Regression R-squared (alpha=10.0): 0.7654030812954538\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train a Ridge Regression model with various alpha values provided in a list, and evaluate its performance using R-squared\n",
    "ridge_alphas = [0.01, 0.1, 1.0, 10.0]\n",
    "for alpha in ridge_alphas:\n",
    "    ridge_model = Ridge(alpha=alpha)\n",
    "    ridge_model.fit(X_train, y_train)\n",
    "    ridge_r2 = ridge_model.score(X_test, y_test)\n",
    "    print(f\"Ridge Regression R-squared (alpha={alpha}):\", ridge_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f4fce-46f8-4826-bb82-5c86eb294a79",
   "metadata": {},
   "source": [
    "- Ridge regression performs similar to linear regression. However, for complex datasets where there is a possibility of overfitting both `lasso and ridge` regression will give improvements over vanilla models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
