{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae331e8a-b4e1-40c4-b91d-8ee5042c5ac7",
   "metadata": {},
   "source": [
    "### <div align=\"center\">Getting Started</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef525fc8-15d9-43ae-a5a0-cdec96d59014",
   "metadata": {},
   "source": [
    "##### 2.1: Neural Networks - The Foundation of Deep Learning\n",
    "- Neural networks are inspired by the workings of the human brain and form the foundation of deep learning.\n",
    "- When features are complex (e.g., detecting whether an image is of a cat or a dog), we use deep learning. For simpler features and structured data, statistical machine learning is preferred.\n",
    "- Neural networks consist of input, hidden, and output layers. Neurons are responsible for detecting patterns in the data, working together like small processors on a larger task.\n",
    "- Deep learning is a machine learning technique that uses neural networks to learn from large amounts of data, mimicking the human brain's ability to recognize patterns and make decisions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b46c0c5-bf42-4552-821c-bf5dcaced413",
   "metadata": {},
   "source": [
    "##### 2.2: Deep Learning Vs Statistical ML\n",
    "<img src=\"../../screenshots/deep learning vs statistical ml.png\" alt=\"Alt Text\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb352a1c-fe24-455c-8e0f-a96f463b8a6a",
   "metadata": {},
   "source": [
    "##### 2.3: Neural Network Architecture\n",
    "- Just like how homes have different architectures (e.g., wood, metal, concrete), neural networks also have different architectures.\n",
    "  1. Feed Forward Neural Network\n",
    "  2. Recurrent Neural Network\n",
    "  3. Convolutional Neural Network\n",
    "  4. Transformers\n",
    "     \n",
    "<img src=\"../../screenshots/Neural Network Architecture.png\" alt=\"Alt Text\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da77f74-0d62-4ed7-9a5f-5100a41dc546",
   "metadata": {},
   "source": [
    "##### 2.4: Real World Application of Deep Learning\n",
    "- Deep learning is impacting our lives directly today. It has many real-life use cases.\n",
    "- Here are some of the use cases of various neural network architectures:\n",
    "  1. Feed Forward Neural Network (FNN): Weather prediction, demand forecasting.\n",
    "  2. Convolutional Neural Network (CNN): Autonomous driving, photo classification, disease diagnosis.\n",
    "  3. Recurrent Neural Network (RNN): Machine translation, speech recognition (e.g., Google Assistant).\n",
    "  4. Transformers: Generative AI (e.g., using tools like ChatGPT)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45abf57d-7134-43b0-bacd-2d82f449cf36",
   "metadata": {},
   "source": [
    "##### 2.5: Tooling - PyTorch Vs Tensorflow\n",
    "- There are many open-source frameworks available today that allow you to build a deep learning system effectively.\n",
    "- PyTorch (by Meta) and TensorFlow (by Google) are two popular frameworks. While both have their own benefits, PyTorch seems to be gaining popularity and is preferred for students as the learning is easier compared to TensorFlow.\n",
    "##### 2.6: Tooling - GPU, TPU\n",
    "- GPUs (Graphics Processing Units) were traditionally used for gaming but now they are being used for deep learning.\n",
    "- NVIDIA is a company known for GPUs, and the rise in their stock price is mainly attributed to the Gen AI boom that has resulted in companies ordering millions of dollars worth of GPUs from NVIDIA.\n",
    "- TPU (Tensor Processing Unit) is a less popular option used to speed up deep learning training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f48c3d-adb7-40f0-87f7-8a1fc8ee1ca8",
   "metadata": {},
   "source": [
    "### <div align=\"center\">Neural Network: Fundamentals</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5ac1fb-49ca-48b0-9579-0135da8c37f0",
   "metadata": {},
   "source": [
    "##### 3.1: What is Neuron ?\n",
    "- Neurons are the basic building blocks of neural networks in deep learning.\n",
    "- Each neuron receives input, processes it, and passes it to the next layer.\n",
    "- Neurons apply a weight to the input and use an activation function to determine the output.\n",
    "- Logistic regression can be thought of as the simplest form of a neural network with a single neuron.\n",
    "- A neuron in deep learning is inspired by biological neurons in the human brain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d553f59-354b-4e48-b18b-5ea534e86e1c",
   "metadata": {},
   "source": [
    "##### 3.2: Perceptron and Multi layer Perceptron (MLP)\n",
    "- The perceptron is the simplest neural network model that classifies linearly separable data.\n",
    "- The multilayer perceptron (MLP) extends the perceptron with hidden layers and non-linear activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2391bc54-efb3-44dc-9ba3-4a221a5d3759",
   "metadata": {},
   "source": [
    "##### 3.3: Neural Network Intuition\n",
    "- Neural networks have input, output, and hidden layers.\n",
    "- For the insurance example, features such as Age and Education help fire the Awareness neuron in a hidden layer. Other features such as Income and Savings help fire the Affordability neuron in a hidden layer.\n",
    "- Whether a person will buy insurance or not will be determined based on Awareness and Affordability.\n",
    "- At each stage, starting from input to output, a neural network is extracting patterns from the data so that it can make a final decision using those patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73449208-4440-4a65-8f74-e42d5a96683d",
   "metadata": {},
   "source": [
    "##### 3.4: The Purpose of Activation Function\n",
    "- Real-world problems are often non-linear in nature, and activation functions help introduce non-linearity in a neural network.\n",
    "- With activation functions, neurons either \"fire\" or \"do not fire.\" This can be thought of as individual detectives who are given a specific task and, after investigation, they give their findings to a judge (which is the neuron in the next layer).\n",
    "- In the case of the insurance prediction example, in the hidden layer, we have two detectives: one responsible for figuring out awareness and the other for affordability. They give their conclusion that a person's awareness is 0 or 1 (if using a step activation function), or it is a number between 0 to 1, say 0.7 (when using a sigmoid activation function)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47064b3-5023-4988-91ed-6d72554a6532",
   "metadata": {},
   "source": [
    "##### 3.5: Activation Functions: Sigmoid, ReLU, Tanh, SoftMax\n",
    "- Sigmoid, Softmax, tanh, ReLU are the most commonly used activation functions.\n",
    "- Sigmoid is primarily used in the output layer for binary classification problems (e.g., will a person buy insurance, is the transaction fraud).\n",
    "- Softmax is primarily used in the output layer for multi-class classification problems (e.g., handwritten digits classification, clothes classification).\n",
    "- tanh is similar to Sigmoid; the only difference is that the output range is -1 to 1 (for Sigmoid, the range is 0 to 1).\n",
    "- ReLU is a default choice for neurons in hidden layers as it is fast to calculate and also doesnâ€™t suffer much from vanishing gradient problems.\n",
    "- Leaky ReLU is a variant of ReLU that helps with the dead neurons problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
